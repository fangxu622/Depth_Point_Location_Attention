{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7379, 0.9833, 0.7144])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmcv import Config\n",
    "import open3d\n",
    "import numpy as np\n",
    "import torch\n",
    "import MinkowskiEngine as ME\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "points = np.random.random(size=(1000,3))\n",
    "\n",
    "tt = torch.tensor(points,dtype=torch.float)\n",
    "tt.type(torch.float)[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(data):\n",
    "    coords = []\n",
    "    for i, row in enumerate(data):\n",
    "        for j, col in enumerate(row):\n",
    "            if col != \" \":\n",
    "                coords.append([i, j])\n",
    "    return np.array(coords)\n",
    "\n",
    "def data_loader(\n",
    "    nchannel=3,\n",
    "    max_label=5,\n",
    "    is_classification=True,\n",
    "    seed=-1,\n",
    "    batch_size=2,\n",
    "    dtype=torch.float32,\n",
    "):\n",
    "    if seed >= 0:\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    data = [\"   X   \", \"  X X  \", \" XXXXX \"]\n",
    "\n",
    "    # Generate coordinates\n",
    "    coords = [get_coords(data) for i in range(batch_size)]\n",
    "    coords = ME.utils.batched_coordinates(coords)\n",
    "\n",
    "    # features and labels\n",
    "    N = len(coords)\n",
    "    feats = torch.arange(N * nchannel).view(N, nchannel).to(dtype)\n",
    "    label = (torch.rand(batch_size if is_classification else N) * max_label).long()\n",
    "    return coords, feats, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "std::vector<Eigen::Vector3d> with 307200 elements.\n",
      "Use numpy.asarray() to access data.\n",
      "std::vector<Eigen::Vector3d> with 84408 elements.\n",
      "Use numpy.asarray() to access data.\n"
     ]
    }
   ],
   "source": [
    "path = \"/media/fangxu/Disk4T/fangxuPrj/Depth_Point_Location_Attention/config/conf_1.py\"\n",
    "cfg = Config.fromfile(path)\n",
    "print(cfg.learning_rate)\n",
    "#print(cfg.cuda)\n",
    "\n",
    "pcd_path = \"/media/fangxu/Disk4T/LQ/pointcloud/chess/seq-01/frame-000363.cloud.ply\"\n",
    "pcd_data =  open3d.io.read_point_cloud(pcd_path)\n",
    "print(pcd_data.points)\n",
    "\n",
    "voxel_data = pcd_data.voxel_down_sample(voxel_size= 0.01)\n",
    "print(voxel_data.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3])\n",
      "torch.Size([16, 1])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "coords, feats, labels = data_loader(nchannel=1)\n",
    "print(coords.shape)\n",
    "print(feats.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "std::vector<Eigen::Vector3d> with 307200 elements.\n",
       "Use numpy.asarray() to access data."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "std::vector<Eigen::Vector3d> with 84408 elements.\n",
       "Use numpy.asarray() to access data."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"/media/fangxu/Disk4T/fangxuPrj/MinkLoc3D/config/config_baseline.txt\")\n",
    "params = config['DEFAULT']\n",
    "num_points = params.getint('num_points', 4096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', '1', ',', '2', ',', '3', ',', '4', ']']\n",
      "7\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "params = config['TRAIN']\n",
    "num_workers = params.getint('num_workers',7)\n",
    "dataset_folder = params.get ('seq_train_list')\n",
    "print(list(dataset_folder))\n",
    "print(num_workers )\n",
    "print(type(dataset_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72228, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(voxel_data.points).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spconv\n",
    "import torch\n",
    "\n",
    "features = torch.randn(1000,3)\n",
    "\n",
    "indices = torch.randn(1000,4)\n",
    "spatial_shape=(200,3)\n",
    "batch_size=5\n",
    "x = spconv.SparseConvTensor(features, indices, spatial_shape, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 2 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-62b883fe733f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_dense_NCHW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert sparse tensor to dense NCHW tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/spconv/__init__.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(self, channels_first)\u001b[0m\n\u001b[1;32m     99\u001b[0m         res = scatter_nd(\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             output_shape)\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/spconv/__init__.py\u001b[0m in \u001b[0;36mscatter_nd\u001b[0;34m(indices, updates, shape)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mflatted_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mslices\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEllipsis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 2 with size 3"
     ]
    }
   ],
   "source": [
    "x_dense_NCHW = x.dense() # convert sparse tensor to dense NCHW tensor.\n",
    "print(x.sparity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    " from spconv.utils import VoxelGeneratorV2 as VoxelGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_generator = VoxelGenerator(\n",
    "                voxel_size=  [0.05, 0.05, 0.1] , #config.VOXEL_SIZE,\n",
    "                point_cloud_range=[0, -40, -3, 70.4, 40, 1], #self.point_cloud_range,\n",
    "                max_num_points=5, #config.MAX_POINTS_PER_VOXEL,\n",
    "                max_voxels=160000 #config.MAX_NUMBER_OF_VOXELS[self.mode]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.randn(100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = p[:,0:1]\n",
    "p2 = p[:,0:1]\n",
    "p3 = p[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = np.concatenate([p1,p2,p3],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spconv\n",
    "import torch\n",
    "import numpy as np\n",
    "voxel_generator = spconv.utils.VoxelGenerator(\n",
    "    voxel_size=[0.1, 0.1, 0.1], \n",
    "    point_cloud_range=[-50, -50, -3, 50, 50, 1],\n",
    "    max_num_points=30,\n",
    "    max_voxels=40000,\n",
    "    full_mean=False\n",
    ")\n",
    "\n",
    "points =np.asarray(pcd_data.points) # [N, 3+] tensor.\n",
    "points = np.random.randn(1000,3)\n",
    "voxels, coords, num_points_per_voxel = voxel_generator.generate(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376, 30, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voxels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1424, -0.7321,  0.8806],\n",
       "       [-1.1269, -0.7356,  0.8764],\n",
       "       [-1.1244, -0.7369,  0.8785],\n",
       "       ...,\n",
       "       [ 1.0745, -1.0865, -0.1665],\n",
       "       [ 1.0745, -1.0865, -0.1665],\n",
       "       [ 1.0745, -1.0865, -0.1665]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(pcd_data.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret 'torch.float64' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-377bc3493d84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvoxels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret 'torch.float64' as a data type"
     ]
    }
   ],
   "source": [
    "voxels = np.zeros(shape=(1,2), dtype=points.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.random.randn(100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11280"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "376*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_points_per_voxel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import spconv\n",
    "from spconv.test_utils import TestCase, generate_sparse_data, params_grid\n",
    "import numpy as np \n",
    "# convert a NDHW C dense tensor to sparse:\n",
    "# first we generate 3d fake data with 32 features and batch size 2\n",
    "sparse_dict = generate_sparse_data([50, 30, 30], [1000, 1000], 32)\n",
    "features = np.ascontiguousarray(sparse_dict[\"features\"]).astype(\n",
    "    np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_dict['features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 32, 50, 30, 30)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_dict['features_dense'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3])\n",
      "torch.Size([16, 1])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.],\n",
       "        [ 1.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 6.],\n",
       "        [ 7.],\n",
       "        [ 8.],\n",
       "        [ 9.],\n",
       "        [10.],\n",
       "        [11.],\n",
       "        [12.],\n",
       "        [13.],\n",
       "        [14.],\n",
       "        [15.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [\n",
    "#     [0, 0, 2.1, 0, 0],\n",
    "#     [0, 1, 1.4, 3, 0],\n",
    "#     [0, 0, 4.0, 0, 0]\n",
    "# ]\n",
    "data = np.asarray( voxel_data.points )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sparse_coo(data):\n",
    "    # An intuitive way to extract coordinates and features\n",
    "    coords, feats = [], []\n",
    "    for i, row in enumerate(data):\n",
    "        for j, val in enumerate(row):\n",
    "            if val != 0:\n",
    "                coords.append([i, j])\n",
    "                feats.append([val])\n",
    "    return torch.IntTensor(coords), torch.FloatTensor(feats)\n",
    "\n",
    "coords , feats =to_sparse_coo(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([253223, 2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([253223, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ME.SparseTensor(coordinates=coords, features=feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(\n",
       "  coordinates=tensor([[    0,     0],\n",
       "        [    0,     1],\n",
       "        [    0,     2],\n",
       "        ...,\n",
       "        [84407,     0],\n",
       "        [84407,     1],\n",
       "        [84407,     2]], dtype=torch.int32)\n",
       "  features=tensor([[ 1.2983],\n",
       "        [-0.0454],\n",
       "        [ 2.3938],\n",
       "        ...,\n",
       "        [ 1.0284],\n",
       "        [-0.6577],\n",
       "        [ 1.7524]])\n",
       "  coordinate_map_key=coordinate map key:[1]\n",
       "  coordinate_manager=CoordinateMapManagerCPU(\n",
       "\t[1, \b\b]:\tCoordinateMapCPU:253223x2\n",
       "\talgorithm=MinkowskiAlgorithm.DEFAULT\n",
       "  )\n",
       "  spatial dimension=1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "457997503d7de8a09387433d4eb6117e635735c8633c12fb7557bdceb6846778"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
